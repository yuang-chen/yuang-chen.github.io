<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Gather with SIMD | Yac's Blog</title><meta name=keywords content="c++,SIMD"><meta name=description content="Writing SIMD code that works across different platforms can be a challenging task. The following log illustrates how a seemingly simple operation in C++ can quickly escalate into a significant problem.
Let&rsquo;s look into the code below, where the elements of x is accessed through indices specified by idx.
normal code std::vector<float> x = /*some data*/ std::vector<int> idx = /* index */ for(auto i: idx) { auto data = x[i]; } Gather with Intel In AVX512, Gather is a specific intrinsic function to transfer data from a data array to a target vec, according to an index vec."><meta name=author content="Yac"><link rel=canonical href=https://yuang-chen.github.io/posts/2023-04-27-gather-simd/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://yuang-chen.github.io/favicon/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://yuang-chen.github.io/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://yuang-chen.github.io/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://yuang-chen.github.io/favicon/apple-touch-icon.ico><link rel=mask-icon href=https://yuang-chen.github.io/favicon/favicon-32x32.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content=" Gather with SIMD"><meta property="og:description" content="Writing SIMD code that works across different platforms can be a challenging task. The following log illustrates how a seemingly simple operation in C++ can quickly escalate into a significant problem.
Let&rsquo;s look into the code below, where the elements of x is accessed through indices specified by idx.
normal code std::vector<float> x = /*some data*/ std::vector<int> idx = /* index */ for(auto i: idx) { auto data = x[i]; } Gather with Intel In AVX512, Gather is a specific intrinsic function to transfer data from a data array to a target vec, according to an index vec."><meta property="og:type" content="article"><meta property="og:url" content="https://yuang-chen.github.io/posts/2023-04-27-gather-simd/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-04-27T13:27:50+08:00"><meta property="article:modified_time" content="2023-04-27T13:27:50+08:00"><meta property="og:site_name" content="Yac's Blog"><meta name=twitter:card content="summary"><meta name=twitter:title content=" Gather with SIMD"><meta name=twitter:description content="Writing SIMD code that works across different platforms can be a challenging task. The following log illustrates how a seemingly simple operation in C++ can quickly escalate into a significant problem.
Let&rsquo;s look into the code below, where the elements of x is accessed through indices specified by idx.
normal code std::vector<float> x = /*some data*/ std::vector<int> idx = /* index */ for(auto i: idx) { auto data = x[i]; } Gather with Intel In AVX512, Gather is a specific intrinsic function to transfer data from a data array to a target vec, according to an index vec."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://yuang-chen.github.io/posts/"},{"@type":"ListItem","position":2,"name":" Gather with SIMD","item":"https://yuang-chen.github.io/posts/2023-04-27-gather-simd/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":" Gather with SIMD","name":" Gather with SIMD","description":"Writing SIMD code that works across different platforms can be a challenging task. The following log illustrates how a seemingly simple operation in C++ can quickly escalate into a significant problem.\nLet\u0026rsquo;s look into the code below, where the elements of x is accessed through indices specified by idx.\nnormal code std::vector\u0026lt;float\u0026gt; x = /*some data*/ std::vector\u0026lt;int\u0026gt; idx = /* index */ for(auto i: idx) { auto data = x[i]; } Gather with Intel In AVX512, Gather is a specific intrinsic function to transfer data from a data array to a target vec, according to an index vec.","keywords":["c++","SIMD"],"articleBody":"Writing SIMD code that works across different platforms can be a challenging task. The following log illustrates how a seemingly simple operation in C++ can quickly escalate into a significant problem.\nLet‚Äôs look into the code below, where the elements of x is accessed through indices specified by idx.\nnormal code std::vector\u003cfloat\u003e x = /*some data*/ std::vector\u003cint\u003e idx = /* index */ for(auto i: idx) { auto data = x[i]; } Gather with Intel In AVX512, Gather is a specific intrinsic function to transfer data from a data array to a target vec, according to an index vec. This intrinsic vectorizes the example of normal code.\nSIMD code int simd_width = 16; for(size_t i = 0; i \u003c x.size(); i+= simd_width) { __m512i idx_vec = _mm512_loadu_epi32(\u0026idx[i]); __m512 x_vec = _mm512_i32gather_ps(idx_vec, \u0026x[0], sizeof(float)); } With Intel‚Äôs SIMD, the code snippet gets the data from the vector x based on the index register idx_vec and store the resultant data into the result register x_vec.\nPersonally, after a few days of SIMD coding, I do appreciate such code, and consider this SIMD solution is simple and elegant: two instructions are used, which is nicely aligned with what happens in the normal code:\nloading the data from the idx vector; loading the data from x vector according to the result of the 1st step. A big BUT, the gather (and scatter) operation is not supported by most of other sets ‚Äì they simply just do NOT offer these instructions üòÆ‚Äçüí®. To achieve the same data loading task, more efforts are needed.\nCustomized Gather with ARM Using ARM intrinsics, we have to implement our own gather. I found three solutions do so and benchmarked their performances.\nTmp array /* tmp array */ int simd_width = 4; aligns(16) std::array\u003cfloat,simd_width\u003e tmp; for(size_t i = 0; i \u003c x.size(); i += simd_width) { tmp[0] = x[idx[i]]; tmp[1] = x[idx[i + 1]]; tmp[2] = x[idx[i + 2]]; tmp[3] = x[idx[i + 3]]; float32x4_t tmp_vec = vld1q_f32(tmp.data()); // loading to register vst1q_f32(\u0026buf[i], tmp_vec); } A naive solution (suggested by ChatGPT-4 and many GitHub repos) is to load the idx and x[idx] directly without the help of intrinsics, store the data in a temporary array, and then load to the target register. This solution mixes SIMD and non-SIMD. The indexing accesses (e.g., [i]) to the arrays lets the compilers/CPU do whatever they want, which loses the register-level control.\nUnion union alignas(64) f32x4_union { float32x4_t reg128; std::array\u003cfloat, 4\u003e f32x4; }; f32x4_union res_vec; for(size_t i = 0; i \u003c size; i += 4) { res_vec.f32x4[0] = x[idx[i]]; res_vec.f32x4[1] = x[idx[i + 1]]; res_vec.f32x4[2] = x[idx[i + 2]]; res_vec.f32x4[3] = x[idx[i + 3]]; vst1q_f32(\u0026buf[i], res_vec.reg128); } By put the array and register into a union, we now have the access to the elements of the register by indexing. Compared to the tmp array solution, the union solution avoids the code of loading data to the register (i.e., vld1q_f32), thus improving the efficiency. However, the indexing access is still under the control of the compiler/CPU.\nget \u0026 set uint32x4_t idx_vec; float32x4_t x_vec; for(size_t i = 0; i \u003c size; i += 4) { idx_vec = vld1q_u32(\u0026idx[i]); x_vec = vsetq_lane_f32(x[vgetq_lane_u32(idx_vec, 0)], x_vec, 0); x_vec = vsetq_lane_f32(x[vgetq_lane_u32(idx_vec, 1)], x_vec, 1); x_vec = vsetq_lane_f32(x[vgetq_lane_u32(idx_vec, 2)], x_vec, 2); x_vec = vsetq_lane_f32(x[vgetq_lane_u32(idx_vec, 3)], x_vec, 3); vst1q_f32(\u0026buf[i], x_vec); } This solution combines the get and set intrinsics to mimic the advanced gather operation. The code is ‚Ä¶ ugly, but efficient. It makes sure that idx_vec and x_vec are carefully reused, allowing the finest control in the registers.\nget \u0026 tmp array alignas(16) std::array\u003cfloat, 4\u003e values; for(size_t i = 0; i \u003c size; i += 4) { uint32x4_t idx_vec = vld1q_u32(\u0026idx[i]); values[0] = x[vgetq_lane_u32(idx_vec, 0)]; values[1] = x[vgetq_lane_u32(idx_vec, 1)]; values[2] = x[vgetq_lane_u32(idx_vec, 2)]; values[3] = x[vgetq_lane_u32(idx_vec, 3)]; float32x4_t x_vec = vld1q_f32(values.data()); vst1q_f32(\u0026buf[i], x_vec); } The last solution mixes get with tmp array. It is an intermediate between the 1nd and 3rd solution in terms of the use of registers.\nBenchmarking With data size of 1\u003c\u003c27, the performance of the four solutions are:\nperformance union tmp get\u0026set get\u0026tmp time (ms) 703 639 583 648 assembly code lines 16 16 18 18 The union solution yields the shortest assembly code but the longest execution time. This short code piece is reasonable, as it eliminates one line code compared with the tmp method. But why so long time? The key reason is that, the writing to the union elements by indexing (res_vec.f32x4[i] = ...) is inefficient, compared to the use of intrinsic vld1q_f32(*ptr). Explicit control on the registers promises better performance! The get\u0026set facilitates the finest control of registers, and thus gives the shortest time.\nA weird result is acquired by get\u0026tmp. It actually slightly slower than tmp and I do not understand why. I feed the assembly code of the last three solutions to ChatGPT-4, and this is its analysis:\ntmp ‚Äì L10 (first loop): This loop involves more register manipulation (bfi, fmov, ins) compared to the other loops. It may contribute to higher register pressure and could potentially limit instruction-level parallelism, affecting performance.\nget\u0026set ‚Äì L11 (second loop): This loop uses ld1 and ld1q instructions to load the required values into SIMD registers directly from memory. This reduces the amount of register manipulation required compared to L10, which could lead to better performance.\nget\u0026tmp ‚Äì L12 (third loop): This loop uses a similar approach to L10, using a mix of bfi, fmov, and ins instructions to manipulate registers. However, it also involves an additional ldr instruction for each iteration, which increases the amount of memory operations per iteration compared to L10. This could potentially explain why L12 is slower than L10.\nIn conclusion, the second loop (L11) has the least amount of register manipulation and memory operations per iteration, which may contribute to its better performance. The third loop (L12) has more memory operations per iteration compared to the first loop (L10), which could lead to a slower execution time.\nMake sense?\nThe complete code is here\n","wordCount":"994","inLanguage":"en","datePublished":"2023-04-27T13:27:50+08:00","dateModified":"2023-04-27T13:27:50+08:00","author":{"@type":"Person","name":"Yac"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://yuang-chen.github.io/posts/2023-04-27-gather-simd/"},"publisher":{"@type":"Organization","name":"Yac's Blog","logo":{"@type":"ImageObject","url":"https://yuang-chen.github.io/favicon/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://yuang-chen.github.io/ accesskey=h title="Yac's Log (Alt + H)"><img src=https://yuang-chen.github.io/facebook alt aria-label=logo height=35>Yac's Log</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://yuang-chen.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://yuang-chen.github.io/archives title=Archives><span>Archives</span></a></li><li><a href=https://yuang-chen.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://yuang-chen.github.io/search title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://yuang-chen.github.io/about/aboutme title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Gather with SIMD</h1><div class=post-meta><span title='2023-04-27 13:27:50 +0800 HKT'>April 27, 2023</span>&nbsp;¬∑&nbsp;994 words&nbsp;¬∑&nbsp;Yac</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><ul><li></li><li><a href=#gather-with-intel>Gather with Intel</a></li><li><a href=#customized-gather-with-arm>Customized Gather with ARM</a></li><li><a href=#benchmarking>Benchmarking</a></li></ul></li></ul></nav></div></details></div><div class=post-content><p>Writing SIMD code that works across different platforms can be a challenging task. The following log illustrates how a seemingly simple operation in C++ can quickly escalate into a significant problem.</p><p>Let&rsquo;s look into the code below, where the elements of <code>x</code> is accessed through indices specified by <code>idx</code>.</p><h5 id=normal-code>normal code<a hidden class=anchor aria-hidden=true href=#normal-code>#</a></h5><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span> <span class=n>x</span> <span class=o>=</span> <span class=cm>/*some data*/</span>
</span></span><span class=line><span class=cl><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>int</span><span class=o>&gt;</span> <span class=n>idx</span> <span class=o>=</span> <span class=cm>/* index */</span>
</span></span><span class=line><span class=cl><span class=k>for</span><span class=p>(</span><span class=k>auto</span> <span class=nl>i</span><span class=p>:</span> <span class=n>idx</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>auto</span> <span class=n>data</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h3 id=gather-with-intel>Gather with Intel<a hidden class=anchor aria-hidden=true href=#gather-with-intel>#</a></h3><p>In AVX512, Gather is a specific intrinsic function to transfer data from a data <code>array</code> to a <code>target vec</code>, according to an <code>index vec</code>. This intrinsic vectorizes the example of <strong>normal code</strong>.</p><h5 id=simd-code>SIMD code<a hidden class=anchor aria-hidden=true href=#simd-code>#</a></h5><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=kt>int</span> <span class=n>simd_width</span> <span class=o>=</span> <span class=mi>16</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>for</span><span class=p>(</span><span class=n>size_t</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>x</span><span class=p>.</span><span class=n>size</span><span class=p>();</span> <span class=n>i</span><span class=o>+=</span> <span class=n>simd_width</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl><span class=n>__m512i</span> <span class=n>idx_vec</span> <span class=o>=</span> <span class=n>_mm512_loadu_epi32</span><span class=p>(</span><span class=o>&amp;</span><span class=n>idx</span><span class=p>[</span><span class=n>i</span><span class=p>]);</span>
</span></span><span class=line><span class=cl><span class=n>__m512</span>  <span class=n>x_vec</span>   <span class=o>=</span> <span class=n>_mm512_i32gather_ps</span><span class=p>(</span><span class=n>idx_vec</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>x</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>With Intel&rsquo;s SIMD, the code snippet gets the data from the vector <code>x</code> based on the index register <code>idx_vec</code> and store the resultant data into the result register <code>x_vec</code>.</p><p>Personally, after a few days of SIMD coding, I do appreciate such code, and consider this SIMD solution is simple and elegant: two instructions are used, which is nicely aligned with what happens in the normal code:</p><ol><li>loading the data from the <code>idx</code> vector;</li><li>loading the data from <code>x</code> vector according to the result of the 1st step.</li></ol><p>A big BUT, the <code>gather</code> (and <code>scatter</code>) operation is not supported by most of other sets &ndash; they simply just do NOT offer these instructions üòÆ‚Äçüí®. To achieve the same data loading task, more efforts are needed.</p><h3 id=customized-gather-with-arm>Customized Gather with ARM<a hidden class=anchor aria-hidden=true href=#customized-gather-with-arm>#</a></h3><p>Using ARM intrinsics, we have to implement our own gather. I found three solutions do so and benchmarked their performances.</p><h4 id=tmp-array>Tmp array<a hidden class=anchor aria-hidden=true href=#tmp-array>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=cm>/* tmp array */</span>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=n>simd_width</span> <span class=o>=</span> <span class=mi>4</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>aligns</span><span class=p>(</span><span class=mi>16</span><span class=p>)</span> <span class=n>std</span><span class=o>::</span><span class=n>array</span><span class=o>&lt;</span><span class=kt>float</span><span class=p>,</span><span class=n>simd_width</span><span class=o>&gt;</span> <span class=n>tmp</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>for</span><span class=p>(</span><span class=n>size_t</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>x</span><span class=p>.</span><span class=n>size</span><span class=p>();</span> <span class=n>i</span> <span class=o>+=</span> <span class=n>simd_width</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=n>tmp</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>idx</span><span class=p>[</span><span class=n>i</span><span class=p>]];</span>
</span></span><span class=line><span class=cl>  <span class=n>tmp</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>idx</span><span class=p>[</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>]];</span>
</span></span><span class=line><span class=cl>  <span class=n>tmp</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>idx</span><span class=p>[</span><span class=n>i</span> <span class=o>+</span> <span class=mi>2</span><span class=p>]];</span>
</span></span><span class=line><span class=cl>  <span class=n>tmp</span><span class=p>[</span><span class=mi>3</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>idx</span><span class=p>[</span><span class=n>i</span> <span class=o>+</span> <span class=mi>3</span><span class=p>]];</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>float32x4_t</span> <span class=n>tmp_vec</span> <span class=o>=</span> <span class=n>vld1q_f32</span><span class=p>(</span><span class=n>tmp</span><span class=p>.</span><span class=n>data</span><span class=p>());</span> <span class=c1>// loading to register
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=n>vst1q_f32</span><span class=p>(</span><span class=o>&amp;</span><span class=n>buf</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>tmp_vec</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>A naive solution (suggested by ChatGPT-4 and many GitHub repos) is to load the <code>idx</code> and <code>x[idx]</code> directly without the help of intrinsics, store the data in a temporary array, and then load to the target register. This solution mixes SIMD and non-SIMD. The indexing accesses (e.g., <code>[i]</code>) to the arrays lets the compilers/CPU do whatever they want, which loses the register-level control.</p><h4 id=union>Union<a hidden class=anchor aria-hidden=true href=#union>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>union</span> <span class=nf>alignas</span><span class=p>(</span><span class=mi>64</span><span class=p>)</span> <span class=n>f32x4_union</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=n>float32x4_t</span>          <span class=n>reg128</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>std</span><span class=o>::</span><span class=n>array</span><span class=o>&lt;</span><span class=kt>float</span><span class=p>,</span> <span class=mi>4</span><span class=o>&gt;</span> <span class=n>f32x4</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>};</span>
</span></span><span class=line><span class=cl><span class=n>f32x4_union</span> <span class=n>res_vec</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>for</span><span class=p>(</span><span class=n>size_t</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>size</span><span class=p>;</span> <span class=n>i</span> <span class=o>+=</span> <span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=n>res_vec</span><span class=p>.</span><span class=n>f32x4</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>idx</span><span class=p>[</span><span class=n>i</span><span class=p>]];</span>
</span></span><span class=line><span class=cl>  <span class=n>res_vec</span><span class=p>.</span><span class=n>f32x4</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>idx</span><span class=p>[</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>]];</span>
</span></span><span class=line><span class=cl>  <span class=n>res_vec</span><span class=p>.</span><span class=n>f32x4</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>idx</span><span class=p>[</span><span class=n>i</span> <span class=o>+</span> <span class=mi>2</span><span class=p>]];</span>
</span></span><span class=line><span class=cl>  <span class=n>res_vec</span><span class=p>.</span><span class=n>f32x4</span><span class=p>[</span><span class=mi>3</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>idx</span><span class=p>[</span><span class=n>i</span> <span class=o>+</span> <span class=mi>3</span><span class=p>]];</span>
</span></span><span class=line><span class=cl>  <span class=n>vst1q_f32</span><span class=p>(</span><span class=o>&amp;</span><span class=n>buf</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>res_vec</span><span class=p>.</span><span class=n>reg128</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>By put the array and register into a union, we now have the access to the elements of the register by indexing. Compared to the <code>tmp array</code> solution, the <code>union</code> solution avoids the code of loading data to the register (i.e., <code>vld1q_f32</code>), thus improving the efficiency. However, the indexing access is still under the control of the compiler/CPU.</p><h4 id=get--set>get & set<a hidden class=anchor aria-hidden=true href=#get--set>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=n>uint32x4_t</span>  <span class=n>idx_vec</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>float32x4_t</span> <span class=n>x_vec</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>for</span><span class=p>(</span><span class=n>size_t</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>size</span><span class=p>;</span> <span class=n>i</span> <span class=o>+=</span> <span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=n>idx_vec</span> <span class=o>=</span> <span class=n>vld1q_u32</span><span class=p>(</span><span class=o>&amp;</span><span class=n>idx</span><span class=p>[</span><span class=n>i</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>  <span class=n>x_vec</span>   <span class=o>=</span> <span class=n>vsetq_lane_f32</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=n>vgetq_lane_u32</span><span class=p>(</span><span class=n>idx_vec</span><span class=p>,</span> <span class=mi>0</span><span class=p>)],</span> <span class=n>x_vec</span><span class=p>,</span> <span class=mi>0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>x_vec</span>   <span class=o>=</span> <span class=n>vsetq_lane_f32</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=n>vgetq_lane_u32</span><span class=p>(</span><span class=n>idx_vec</span><span class=p>,</span> <span class=mi>1</span><span class=p>)],</span> <span class=n>x_vec</span><span class=p>,</span> <span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>x_vec</span>   <span class=o>=</span> <span class=n>vsetq_lane_f32</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=n>vgetq_lane_u32</span><span class=p>(</span><span class=n>idx_vec</span><span class=p>,</span> <span class=mi>2</span><span class=p>)],</span> <span class=n>x_vec</span><span class=p>,</span> <span class=mi>2</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>x_vec</span>   <span class=o>=</span> <span class=n>vsetq_lane_f32</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=n>vgetq_lane_u32</span><span class=p>(</span><span class=n>idx_vec</span><span class=p>,</span> <span class=mi>3</span><span class=p>)],</span> <span class=n>x_vec</span><span class=p>,</span> <span class=mi>3</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>vst1q_f32</span><span class=p>(</span><span class=o>&amp;</span><span class=n>buf</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>x_vec</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>This solution combines the <code>get</code> and <code>set</code> intrinsics to mimic the advanced gather operation. The code is &mldr; ugly, but efficient. It makes sure that <code>idx_vec</code> and <code>x_vec</code> are carefully reused, allowing the finest control in the registers.</p><h4 id=get--tmp-array>get & tmp array<a hidden class=anchor aria-hidden=true href=#get--tmp-array>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>alignas</span><span class=p>(</span><span class=mi>16</span><span class=p>)</span> <span class=n>std</span><span class=o>::</span><span class=n>array</span><span class=o>&lt;</span><span class=kt>float</span><span class=p>,</span> <span class=mi>4</span><span class=o>&gt;</span> <span class=n>values</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>for</span><span class=p>(</span><span class=n>size_t</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>size</span><span class=p>;</span> <span class=n>i</span> <span class=o>+=</span> <span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=n>uint32x4_t</span> <span class=n>idx_vec</span> <span class=o>=</span> <span class=n>vld1q_u32</span><span class=p>(</span><span class=o>&amp;</span><span class=n>idx</span><span class=p>[</span><span class=n>i</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>values</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>vgetq_lane_u32</span><span class=p>(</span><span class=n>idx_vec</span><span class=p>,</span> <span class=mi>0</span><span class=p>)];</span>
</span></span><span class=line><span class=cl>  <span class=n>values</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>vgetq_lane_u32</span><span class=p>(</span><span class=n>idx_vec</span><span class=p>,</span> <span class=mi>1</span><span class=p>)];</span>
</span></span><span class=line><span class=cl>  <span class=n>values</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>vgetq_lane_u32</span><span class=p>(</span><span class=n>idx_vec</span><span class=p>,</span> <span class=mi>2</span><span class=p>)];</span>
</span></span><span class=line><span class=cl>  <span class=n>values</span><span class=p>[</span><span class=mi>3</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>vgetq_lane_u32</span><span class=p>(</span><span class=n>idx_vec</span><span class=p>,</span> <span class=mi>3</span><span class=p>)];</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>float32x4_t</span> <span class=n>x_vec</span> <span class=o>=</span> <span class=n>vld1q_f32</span><span class=p>(</span><span class=n>values</span><span class=p>.</span><span class=n>data</span><span class=p>());</span>
</span></span><span class=line><span class=cl>  <span class=n>vst1q_f32</span><span class=p>(</span><span class=o>&amp;</span><span class=n>buf</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>x_vec</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>The last solution mixes <code>get</code> with <code>tmp array</code>. It is an intermediate between the 1nd and 3rd solution in terms of the use of registers.</p><h3 id=benchmarking>Benchmarking<a hidden class=anchor aria-hidden=true href=#benchmarking>#</a></h3><p>With data size of <code>1&lt;&lt;27</code>, the performance of the four solutions are:</p><table><thead><tr><th>performance</th><th>union</th><th>tmp</th><th>get&amp;set</th><th>get&amp;tmp</th></tr></thead><tbody><tr><td>time (ms)</td><td>703</td><td>639</td><td>583</td><td>648</td></tr><tr><td>assembly code lines</td><td>16</td><td>16</td><td>18</td><td>18</td></tr></tbody></table><p>The <code>union</code> solution yields the shortest assembly code but the longest execution time. This short code piece is reasonable, as it eliminates one line code compared with the <code>tmp</code> method. But why so long time? The key reason is that, the writing to the union elements by indexing (<code>res_vec.f32x4[i] = ...</code>) is inefficient, compared to the use of intrinsic <code>vld1q_f32(*ptr)</code>. Explicit control on the registers promises better performance! The <code>get&amp;set</code> facilitates the finest control of registers, and thus gives the shortest time.</p><p>A weird result is acquired by <code>get&amp;tmp</code>. It actually slightly slower than <code>tmp</code> and I do not understand why. I feed the assembly code of the last three solutions to ChatGPT-4, and this is its analysis:</p><blockquote><p><em><code>tmp</code> &ndash; L10 (first loop)</em>:
This loop involves more register manipulation (bfi, fmov, ins) compared to the other loops. It may contribute to higher register pressure and could potentially limit instruction-level parallelism, affecting performance.</p></blockquote><blockquote><p><em><code>get&amp;set</code> &ndash; L11 (second loop)</em>:
This loop uses ld1 and ld1q instructions to load the required values into SIMD registers directly from memory. This reduces the amount of register manipulation required compared to L10, which could lead to better performance.</p></blockquote><blockquote><p><em><code>get&amp;tmp</code> &ndash; L12 (third loop)</em>:
This loop uses a similar approach to L10, using a mix of bfi, fmov, and ins instructions to manipulate registers. However, it also involves an additional ldr instruction for each iteration, which increases the amount of memory operations per iteration compared to L10. This could potentially explain why L12 is slower than L10.</p></blockquote><blockquote><p>In conclusion, the second loop (L11) has the least amount of register manipulation and memory operations per iteration, which may contribute to its better performance. The third loop (L12) has more memory operations per iteration compared to the first loop (L10), which could lead to a slower execution time.</p></blockquote><p>Make sense?</p><p>The complete code is <a href=code.cpp>here</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://yuang-chen.github.io/tags/c++/>c++</a></li><li><a href=https://yuang-chen.github.io/tags/simd/>SIMD</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://yuang-chen.github.io/>Yac's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>