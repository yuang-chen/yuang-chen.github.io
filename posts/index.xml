<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Yac&#39;s Log</title>
    <link>https://yuang-chen.github.io/posts/</link>
    <description>Recent content in Posts on Yac&#39;s Log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 Sep 2023 11:17:51 +0800</lastBuildDate><atom:link href="https://yuang-chen.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>BFS</title>
      <link>https://yuang-chen.github.io/posts/2023-09-01-bfs/</link>
      <pubDate>Fri, 01 Sep 2023 11:17:51 +0800</pubDate>
      
      <guid>https://yuang-chen.github.io/posts/2023-09-01-bfs/</guid>
      <description>Iterative BFS. Despite its apparent simplicity, this approach relies heavily on the utilization of various STL containers. std::unordered_map records the parent of each node std::unordered_set checks if a node has been visited std::queue allows the nodes be accessed in the width-first flow std::stack reverses the parents, so the path can be printed in root-to-target order. #include &amp;lt;iostream&amp;gt; #include &amp;lt;vector&amp;gt; #include &amp;lt;unordered_map&amp;gt; #include &amp;lt;unordered_set&amp;gt; #include &amp;lt;queue&amp;gt; #include &amp;lt;stack&amp;gt; std::stack&amp;lt;int&amp;gt; BFS(const int root, const int target, const std::vector&amp;lt;int&amp;gt;&amp;amp; rowPtr, const std::vector&amp;lt;int&amp;gt;&amp;amp; colIdx) { std::unordered_map&amp;lt;int, int&amp;gt; parent; std::unordered_set&amp;lt;int&amp;gt; visited; std::queue&amp;lt;int&amp;gt; nodeQue; std::stack&amp;lt;int&amp;gt; path; bool hasFound = false; nodeQue.</description>
    </item>
    
    <item>
      <title>Graph Algorithms</title>
      <link>https://yuang-chen.github.io/posts/2023-08-31-graph-algorithms/</link>
      <pubDate>Thu, 31 Aug 2023 18:12:09 +0800</pubDate>
      
      <guid>https://yuang-chen.github.io/posts/2023-08-31-graph-algorithms/</guid>
      <description>Considering myself a researcher in graph algorithms, I&amp;rsquo;ve come to the surprising realization that my grasp of these algorithms is not as solid as I thought. Hence, this blog series aims to document my exploration of various graph algorithms I&amp;rsquo;ve encountered thus far, regardless of their complexity.
The algorithms are selected from the parallel graph frameworks GAP and GBBS, focusing on their single-threaded versions to assess their complexity.
Breadth-First Search (BFS) Single-Source Shortest Paths (SSSP) Connected Components (CC) Betweenness Centrality (BC) Triangle Counting (TC) * </description>
    </item>
    
    <item>
      <title>Scope Guard</title>
      <link>https://yuang-chen.github.io/posts/2023-08-29-scope-guard/</link>
      <pubDate>Tue, 29 Aug 2023 10:27:54 +0800</pubDate>
      
      <guid>https://yuang-chen.github.io/posts/2023-08-29-scope-guard/</guid>
      <description>Background Scope Guard is a concept reminiscent of the RAII (Resource Acquisition Is Initialization) principle in C++. The idea is to manage resources (like memory, files, network sockets, etc.) using object lifetime. When the object goes out of scope, its destructor ensures that the resource is cleaned up properly. The scope guard is intended to run a given callable (like a function or lambda) when it is destroyed.
RAII (Resource Acquisition Is Initialization) is a programming idiom used in C++ where the lifetime of an object is bound to the lifetime of its scope (typically represented by a block of code wrapped in curly braces {}).</description>
    </item>
    
    <item>
      <title>Static Local Member</title>
      <link>https://yuang-chen.github.io/posts/2023-08-27-static-local-member/</link>
      <pubDate>Sun, 27 Aug 2023 11:45:15 +0800</pubDate>
      
      <guid>https://yuang-chen.github.io/posts/2023-08-27-static-local-member/</guid>
      <description>C++ templates are blueprints and don&amp;rsquo;t represent specific types until they are instantiated with actual types. Once instantiated, the compiler creates a specific version of that template for the provided type. For template classes, each instantiation has its own unique version of the static members, making them distinct for each type the template is instantiated with.
///////////////////// // Code Block 1 ///////////////////// #include&amp;lt;iostream&amp;gt; class ComponentBase{ protected: // component_type_count is a static variable shared by derived classes static inline size_t component_type_count = 0; }; template&amp;lt;typename T&amp;gt; class Component : public ComponentBase{ public: static size_t component_type_id(){ // ID is the static local variable for a particular type T static size_t ID = component_type_count++; return ID; } }; class A : public Component&amp;lt;A&amp;gt; {}; class B : public Component&amp;lt;B&amp;gt; {}; class C : public Component&amp;lt;C&amp;gt; {}; int main() { std::cout &amp;lt;&amp;lt; A::component_type_id() &amp;lt;&amp;lt; std::endl; // 0 std::cout &amp;lt;&amp;lt; B::component_type_id() &amp;lt;&amp;lt; std::endl; // 1 std::cout &amp;lt;&amp;lt; B::component_type_id() &amp;lt;&amp;lt; std::endl; // 1 std::cout &amp;lt;&amp;lt; A::component_type_id() &amp;lt;&amp;lt; std::endl; // 0 std::cout &amp;lt;&amp;lt; A::component_type_id() &amp;lt;&amp;lt; std::endl; // 0 std::cout &amp;lt;&amp;lt; C::component_type_id() &amp;lt;&amp;lt; std::endl; // 2 } Key Points:</description>
    </item>
    
    <item>
      <title>Formatter Specialization</title>
      <link>https://yuang-chen.github.io/posts/2023-08-25-formatter-specialization/</link>
      <pubDate>Fri, 25 Aug 2023 19:56:16 +0800</pubDate>
      
      <guid>https://yuang-chen.github.io/posts/2023-08-25-formatter-specialization/</guid>
      <description>We can customize the (printing) format of a given class by using the specialization of formatter.
#include &amp;lt;format&amp;gt; #include &amp;lt;iostream&amp;gt; struct Frac { int a, b; }; template &amp;lt;&amp;gt; struct std::formatter&amp;lt;Frac&amp;gt; : std::formatter&amp;lt;string_view&amp;gt; { // parse() is inherited from the base class std::formatter&amp;lt;string_view&amp;gt; // * an efficient solution: auto format(const Frac&amp;amp; frac, std::format_context&amp;amp; ctx) const { return std::format_to(ctx.out(), &amp;#34;{}/{}&amp;#34;, frac.a, frac.b); } // the same functionality as above, but inefficient due to the temporary string // auto format(const Frac&amp;amp; frac, std::format_context&amp;amp; ctx) const { // std::string temp; // std::format_to(std::back_inserter(temp), &amp;#34;{}/{}&amp;#34;, // frac.</description>
    </item>
    
    <item>
      <title>User Defined Literals</title>
      <link>https://yuang-chen.github.io/posts/2023-08-22-user-defined-literals/</link>
      <pubDate>Tue, 22 Aug 2023 23:18:37 +0800</pubDate>
      
      <guid>https://yuang-chen.github.io/posts/2023-08-22-user-defined-literals/</guid>
      <description>User Defined Literals (UDL) produces an object in an interesting way:
constexpr auto operator&amp;#34;&amp;#34;_f(const char* fmt, size_t) { return[=]&amp;lt;typename... T&amp;gt;(T&amp;amp;&amp;amp;... Args) { return std::vformat(fmt, std::make_format_args(std::forward&amp;lt;T&amp;gt;(Args)...)); }; } auto s = &amp;#34;example {} see {}&amp;#34;_f(&amp;#34;yep&amp;#34;, 1.1); // s = &amp;#34;example yep 1.1&amp;#34; The UDL _f has the same effect of std::format(&amp;quot;example {} see {}&amp;quot;, &amp;quot;yep&amp;quot;, 1.1). Pretty familiar (as libfmt), right?
Now, let&amp;rsquo;s break the definition of _f down:
int x = 10; double y = 3.</description>
    </item>
    
    <item>
      <title>Operator Overload</title>
      <link>https://yuang-chen.github.io/posts/2023-08-17-operator-overload/</link>
      <pubDate>Thu, 17 Aug 2023 10:36:19 +0800</pubDate>
      
      <guid>https://yuang-chen.github.io/posts/2023-08-17-operator-overload/</guid>
      <description>Reference: here.
The return of overloaded operator should be a reference, otherwise return-by-code will create a (temporary) rvalue that cannot be passed to the next operation f2 by non-const reference. i.e., rvalue cannot be non-const referenced.
#include &amp;lt;vector&amp;gt; #include &amp;lt;iostream&amp;gt; #include &amp;lt;functional&amp;gt; template&amp;lt;typename T, typename FN&amp;gt; requires std::invocable&amp;lt;FN, T&amp;amp;&amp;gt; // diff std::invocable? std::vector&amp;lt;T&amp;gt;&amp;amp; operator| (std::vector&amp;lt;T&amp;gt;&amp;amp; vec, FN fn) noexcept { for(auto&amp;amp; e: vec) { fn(e); } return vec; } int main(){ std::vector v{1, 2, 3}; auto f1 = [](int&amp;amp; i) {i *= i; }; std::function f2 {[](const int&amp;amp; i) {std::cout &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &amp;#39; &amp;#39;; } }; v | f1 | f2; }``` </description>
    </item>
    
    <item>
      <title>Multidimensional Subscript Operator []</title>
      <link>https://yuang-chen.github.io/posts/2023-05-13-multidim-subscript-operator/</link>
      <pubDate>Sat, 13 May 2023 22:11:07 +0800</pubDate>
      
      <guid>https://yuang-chen.github.io/posts/2023-05-13-multidim-subscript-operator/</guid>
      <description>Finally, C++23 allows overload for the subscript operator [] to be multi-dimensional.
Before that, we normally either use:
vector of vector to form a matrix, and access it as mat[i][j] a class containing a big 1-d vector, but behaves as 2-d by overloading the operator (), e.g., mat(i,j) Now, with C++23, we advance the second option (which offers efficient memory access) with better indexing approaching as follow:
template &amp;lt;typename T, size_t R, size_t C&amp;gt; struct matrix { T&amp;amp; operator[](size_t const r, size_t const c) noexcept { return data_[r * C + c]; } T const&amp;amp; operator[](size_t const r, size_t const c) const noexcept { return data_[r * C + c]; } static constexpr size_t Rows = R; static constexpr size_t Columns = C; private: std::array&amp;lt;T, R * C&amp;gt; data_; }; int main() { matrix&amp;lt;int, 3, 2&amp;gt; m; for(size_t i = 0; i &amp;lt; m.</description>
    </item>
    
    <item>
      <title>Bitwise Op</title>
      <link>https://yuang-chen.github.io/posts/2023-05-07-bitwise-op/</link>
      <pubDate>Sun, 07 May 2023 23:33:24 +0800</pubDate>
      
      <guid>https://yuang-chen.github.io/posts/2023-05-07-bitwise-op/</guid>
      <description>ðŸ¦¥ An old note.
Bitwise vs Arithmetic running on a vector of size 2^31, bitwise operations are significantly faster than arithmetic counterparts:
seg = 64; volume = (vec_size - 1)/ seg + 1; unsigned bs = log2(seg); unsigned bv= log2(volume); unsigned bbv = volume - 1; Arithmetic: out[i] = i % volume * seg + i / volume
Bitwise: out[i] = ((i &amp;amp; bbv) &amp;lt;&amp;lt; bs) + (i &amp;gt;&amp;gt; bv)</description>
    </item>
    
    <item>
      <title>Omp Parallel Region</title>
      <link>https://yuang-chen.github.io/posts/2023-05-02-omp-parallel-region/</link>
      <pubDate>Tue, 02 May 2023 10:34:19 +0800</pubDate>
      
      <guid>https://yuang-chen.github.io/posts/2023-05-02-omp-parallel-region/</guid>
      <description>The results look suspicious to me&amp;hellip; But I wrote down this note many days ago ðŸ¦¥. Maybe I need to evaluate it again.
Multiple Parallel Regions The cost of constructing parallel region is expensive in OpenMP. Let&amp;rsquo;s use two example for illustration:
Three loops operating on a vector of size 2^31, e.g.,
for(size_t i = 0; i &amp;lt; vec.size(); i++) vec[i] += 1, vec[i] *= 0.9, vec[i] /= 7, Case 1: a large parallel region including the three loops by omp parallel { omp for }</description>
    </item>
    
    <item>
      <title>Omp Collapse</title>
      <link>https://yuang-chen.github.io/posts/2023-05-02-omp-collapse/</link>
      <pubDate>Tue, 02 May 2023 10:28:18 +0800</pubDate>
      
      <guid>https://yuang-chen.github.io/posts/2023-05-02-omp-collapse/</guid>
      <description>One of my old-day notes ðŸ¦¥.
Collapse of Nested Loops The collapse clause converts a prefect nested loop into a single loop then parallelize it. The condition of a perfect nested loop is that, the inner loop is tightly included by the outer loop, and no other codes lying between:
for(int i = 0 ... ) { for(int j = 0 ...) { task[i][j]; } } Such condition is hard to meet.</description>
    </item>
    
    <item>
      <title>Vector vs Array</title>
      <link>https://yuang-chen.github.io/posts/2023-05-01-vector-vs-array/</link>
      <pubDate>Mon, 01 May 2023 12:53:14 +0800</pubDate>
      
      <guid>https://yuang-chen.github.io/posts/2023-05-01-vector-vs-array/</guid>
      <description>Another post recycled from my earlier notes. I really don&amp;rsquo;t have motivation to improve it further ðŸ¦¥.
Vector vs Array Initilization The Vector is the preferred choice for data storage in mordern C++. It is internally implemented based on the Array. However, the performance gap between the two is indeed obvious.
The Vector can be initialized via std::vector&amp;lt;T&amp;gt; vec(size). Meanwhile, an Array is initialized by T* arr = new T[size]</description>
    </item>
    
    <item>
      <title> Gather with SIMD</title>
      <link>https://yuang-chen.github.io/posts/2023-04-27-gather-simd/</link>
      <pubDate>Thu, 27 Apr 2023 13:27:50 +0800</pubDate>
      
      <guid>https://yuang-chen.github.io/posts/2023-04-27-gather-simd/</guid>
      <description>Writing SIMD code that works across different platforms can be a challenging task. The following log illustrates how a seemingly simple operation in C++ can quickly escalate into a significant problem.
Let&amp;rsquo;s look into the code below, where the elements of x is accessed through indices specified by idx.
normal code std::vector&amp;lt;float&amp;gt; x = /*some data*/ std::vector&amp;lt;int&amp;gt; idx = /* index */ for(auto i: idx) { auto data = x[i]; } Gather with Intel In AVX512, Gather is a specific intrinsic function to transfer data from a data array to a target vec, according to an index vec.</description>
    </item>
    
    <item>
      <title>SIMD is Pain</title>
      <link>https://yuang-chen.github.io/posts/2023-04-25-simd-pain-intro/</link>
      <pubDate>Tue, 25 Apr 2023 20:59:39 +0800</pubDate>
      
      <guid>https://yuang-chen.github.io/posts/2023-04-25-simd-pain-intro/</guid>
      <description>Writing code with SIMD for vectorization is painful. It deserves a blog series to record all sorts of pains I have encountered and (partially) overcome.
Indeed, once the pain of coding and debugging is finished, the program is lightning-faster. Nonetheless, I am here to complain instead of praising. Let me state why writing SIMD code is causing me emotional damage:
a single line of normal c++ code could be easily inflated to a dozen lines of code.</description>
    </item>
    
    <item>
      <title>Parallel Algorithms from Libraries</title>
      <link>https://yuang-chen.github.io/posts/2023-04-25-par-algo/</link>
      <pubDate>Tue, 25 Apr 2023 10:16:34 +0800</pubDate>
      
      <guid>https://yuang-chen.github.io/posts/2023-04-25-par-algo/</guid>
      <description>The content of this post is extracted from my previous random notes. I am too lazy to update and organize it ðŸ¦¥.
C++17 new feature &amp;ndash; parallel algorithms The parallel algorithms and execution policies are introduced in C++17. Unfortuantely, according to CppReference, only GCC and Intel support these features. Clang still leaves them unimplemented.
A blog about it.
The parallel library brough by C++17 requires the usage of Intel&amp;rsquo;s oneTBB for multithreading.</description>
    </item>
    
  </channel>
</rss>
